{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DIVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"../data/baidu_sentence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>content</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>高中 生物 分子与细胞 组成细胞的化学元素 组成细胞的化合物</td>\n",
       "      <td>菠菜 土壤 中 吸收 氮 元素 用来 合成 淀粉 纤维素 葡萄糖 核酸 蛋白质 麦芽糖 脂肪酸</td>\n",
       "      <td>生物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>高中 生物 稳态与环境 神经调节和体液调节的比较</td>\n",
       "      <td>下列 生物体 内 信息 传递 叙述 正确 下丘脑 分泌 促 甲状腺 激素 释放 激素 作用 ...</td>\n",
       "      <td>生物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>高中 生物 生物技术实践 生物工程技术</td>\n",
       "      <td>自然 菌样 筛选 理想 生产 菌种 步骤 采集 菌样 富集 培养 纯种 分离 性能 测定 不...</td>\n",
       "      <td>生物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>高中 生物 生物技术实践 生物技术在其他方面的应用 器官移植 复等位基因 胚胎移植 基因工程...</td>\n",
       "      <td>目前 精子 载体 法 逐渐 成为 具有 诱惑力 制备 转基因 动物 方法 方法 精子 外源 ...</td>\n",
       "      <td>生物</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>高中 地理 宇宙中的地球 地球运动的地理意义</td>\n",
       "      <td>某人 想 普通 飞机 一年 中 连续 两次 生日 认为 应 穿越 赤道 两级 本初子午线 国...</td>\n",
       "      <td>地理</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              labels  \\\n",
       "0                     高中 生物 分子与细胞 组成细胞的化学元素 组成细胞的化合物   \n",
       "1                           高中 生物 稳态与环境 神经调节和体液调节的比较   \n",
       "2                                高中 生物 生物技术实践 生物工程技术   \n",
       "3  高中 生物 生物技术实践 生物技术在其他方面的应用 器官移植 复等位基因 胚胎移植 基因工程...   \n",
       "4                             高中 地理 宇宙中的地球 地球运动的地理意义   \n",
       "\n",
       "                                             content subject  \n",
       "0    菠菜 土壤 中 吸收 氮 元素 用来 合成 淀粉 纤维素 葡萄糖 核酸 蛋白质 麦芽糖 脂肪酸      生物  \n",
       "1  下列 生物体 内 信息 传递 叙述 正确 下丘脑 分泌 促 甲状腺 激素 释放 激素 作用 ...      生物  \n",
       "2  自然 菌样 筛选 理想 生产 菌种 步骤 采集 菌样 富集 培养 纯种 分离 性能 测定 不...      生物  \n",
       "3  目前 精子 载体 法 逐渐 成为 具有 诱惑力 制备 转基因 动物 方法 方法 精子 外源 ...      生物  \n",
       "4  某人 想 普通 飞机 一年 中 连续 两次 生日 认为 应 穿越 赤道 两级 本初子午线 国...      地理  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "def gen_vocabulary(contents, labels):\n",
    "    # 拉平词语\n",
    "    all_words = [word for content in contents for word in content]\n",
    "    print(\"all words:\", len(all_words))\n",
    "    # 去除低频词\n",
    "    word_counts = Counter(all_words)\n",
    "    sorted_words = sorted(word_counts.items(), key=lambda x:x[1], reverse=True)\n",
    "    fw_words = [word[0] for word in sorted_words if word[1] > 5]\n",
    "    print(\"after clear low frequence:\", len(fw_words))\n",
    "    \n",
    "    vocab, wordEmbedding = get_word_embedding(fw_words)\n",
    "    \n",
    "    word2idx = dict(zip(vocab, list(range(len(vocab)))))\n",
    "    label2idx = dict(zip(list(set(labels)), range(len(list(set(labels))))))\n",
    "    \n",
    "    # 将词汇-索引映射表保存为json数据，之后做inference时直接加载来处理数据\n",
    "    with open(\"../data/wordJson/word2idx.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(word2idx, f)\n",
    "        \n",
    "    with open(\"../data/wordJson/label2idx.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(label2idx, f)\n",
    "        \n",
    "    return word2idx, label2idx, vocab, wordEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "def get_word_embedding(words):\n",
    "    word2vec = gensim.models.KeyedVectors.load_word2vec_format(\"../data/word2vec.bin\", binary=True)\n",
    "    vocab = []\n",
    "    wordEmbedding = []\n",
    "    \n",
    "    vocab.append(\"PAD\")\n",
    "    vocab.append(\"UNK\")\n",
    "    wordEmbedding.append(np.zeros(200))\n",
    "    wordEmbedding.append(np.random.randn(200))\n",
    "    \n",
    "    for word in words:\n",
    "        try:\n",
    "            vector = word2vec.wv[word]\n",
    "            vocab.append(word)\n",
    "            wordEmbedding.append(vector)\n",
    "        except:\n",
    "            print(word + \"not exist in word2vec.\")\n",
    "    \n",
    "    return vocab, np.array(wordEmbedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = [content.split() for content in data_df[\"content\"].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data_df[\"subject\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all words: 1019403\n",
      "after clear low frequence: 12602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "word2idx, label2idx, vocab, wordEmbedding = gen_vocabulary(contents, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12604, 200)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordEmbedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12604"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签数值化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelToIndex(labels, label2idx):\n",
    "    labelIds = [label2idx[label] for label in labels]\n",
    "    \n",
    "    return labelIds\n",
    "\n",
    "def contentToIndex(contents, word2idx):\n",
    "    contentIds = [[word2idx.get(word, word2idx[\"UNK\"]) for word in content] for content in contents]\n",
    "    \n",
    "    return contentIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsIds = labelToIndex(labels, label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "contentIds = contentToIndex(contents, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3396,\n",
       "  402,\n",
       "  2,\n",
       "  495,\n",
       "  2481,\n",
       "  605,\n",
       "  1768,\n",
       "  107,\n",
       "  1002,\n",
       "  682,\n",
       "  359,\n",
       "  470,\n",
       "  55,\n",
       "  2290,\n",
       "  3863]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contentIds[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_train_eval_data(x, y, word2idx, max_len, rate=0.8):\n",
    "    contents = []\n",
    "    \n",
    "    for content in x:\n",
    "        if len(content) >= max_len:\n",
    "            contents.append(content[:max_len])\n",
    "        else:\n",
    "            contents.append(content + [word2idx[\"PAD\"]] * (max_len - len(content)))\n",
    "            \n",
    "    split_idx = int(len(x) * rate)\n",
    "    \n",
    "    train_data = np.asarray(contents[:split_idx], dtype=\"int64\")\n",
    "    train_label = np.array(y[:split_idx], dtype=\"float32\")\n",
    "    \n",
    "    eval_data = np.asarray(contents[split_idx:], dtype=\"int64\")\n",
    "    eval_label = np.array(y[split_idx:], dtype=\"float32\")\n",
    "    \n",
    "    return train_data, train_label, eval_data, eval_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_len(data):\n",
    "    max_lens = data.apply(lambda x: x.count(\" \"))\n",
    "    \n",
    "    return int(np.mean(max_lens) + 2 * np.std(max_lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_max_len = get_max_len(data_df[\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_label, eval_data, eval_label = gen_train_eval_data(contentIds, labelsIds, word2idx, get_max_len(data_df[\"content\"]), 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18060, 108)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4516, 108)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 生成batch数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(x, y, batch_size):\n",
    "    perm = np.arange(len(x))\n",
    "    np.random.shuffle(perm)\n",
    "    \n",
    "    x = x[perm]\n",
    "    y = y[perm]\n",
    "    \n",
    "    num_batches = len(x) // batch_size\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        \n",
    "        batchX = np.array(x[start:end], dtype=\"int64\")\n",
    "        batchY = np.array(y[start:end], dtype=\"int64\")\n",
    "        \n",
    "    return batchX, batchY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
